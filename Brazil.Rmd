---
title: "Analysis Brazil"
author: "Group 7"
date: "12/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Importing Libraries
library(tidyverse)
library(dplyr)
library(skimr)
library(vroom)
library(stringr)
library(openxlsx)
library(lubridate)
library(tidyverse)
library(Publish)
library(data.table)
```


```{r}

## Importing Data
brazil_covid19 <- vroom("data/brazil_covid19.csv") #Covid Information
brazil_cities <- vroom("data/brazil_covid19_cities.csv") #City Information
brazil_city_coordinates <- vroom("data/brazil_cities_coordinates.csv") #City Coordinates
brazil_population <- vroom(file = "data/pop_by_city.csv") #Population Information
brazil_gdp <- vroom("data/PIB dos Munic¡pios - base de dados 2010-2017.csv") #GDP Information
brazil_gdp_location <- read.xlsx(xlsxFile = "data/brazil_gdp_city.xlsx", fillMergedCells = TRUE, colNames = TRUE) #Income info
brazil_hospital_beds <- vroom(file = "data/Itensive_Care Beds_Brazil_2020.csv", delim=';') #Number of hospital beds

```

```{r}
#Cleaning the hospital beds (intensive care) dataframe
brazil_hospital_beds <- 
  brazil_hospital_beds %>% 
  #cleaning column names
  janitor::clean_names() %>% 
  #transforming date as numeric
  mutate(x2020_jul = as.numeric(x2020_jul),
         x2020_ago = as.numeric(x2020_ago)) %>% 
  #pivoting the dataframe
  pivot_longer(!municipio,names_to = "date",values_to = "beds") %>% 
  #mutating the dates - transforming to a date
  mutate(date = case_when(
    date == "x2020_jan" ~ dmy(15012020),
    date == "x2020_fev" ~ dmy(15022020),
    date == "x2020_mar" ~ dmy(15032020),
    date == "x2020_abr" ~ dmy(15042020),
    date == "x2020_mai" ~ dmy(15052020),
    date == "x2020_jun" ~ dmy(15062020),
    date == "x2020_jul" ~ dmy(15072020),
    date == "x2020_ago" ~ dmy(15082020),
    date == "x2020_set" ~ dmy(15092020),
    date == "x2020_out" ~ dmy(15102020)),
    #Fixing the city name for Alta Floresta D'Oeste
    city_name = trimws(str_extract("110001 Alta Floresta D'Oeste", "\\s.*"),"l"),
    #Fix code
    code = as.numeric(str_extract(municipio, "(\\d{6})"))) %>% 
  #Selecting the Columns that we want
  select(code, city_name, date, beds)

#checking if everything was performed
skim(brazil_hospital_beds)
```


```{r}
#cleaning income dataframe
brazil_gdp_location <- brazil_gdp_location %>% 
  #cleaning column names
  janitor::clean_names() %>% 
  #renaming columns
  rename(
    city_name = municipio,
    class = classes_de_rendimento_nominal_mensal_domiciliar_per_capita,
    statistic = ano_x_situacao_do_domicilio
    ) %>% 
  #filtering and mutating income classes (compared to the base salary in Brazil)
  filter(class != "Total") %>% 
  mutate(class = case_when(
    class == "Total" ~ "Total",
    class == "Até 1/8 de salário mínimo" ~ "below_0.125",
    class == "Mais de 1/8 a 1/4 de salário mínimo" ~ "between_0.125_0.25",
    class == "Mais de 1/4 a 1/2 salário mínimo" ~ "between_0.25_0.5",
    class == "Mais de 1/2 a 1 salário mínimo" ~ "between_0.5_1",
    class == "Mais de 1 a 2 salários mínimos" ~ "between_1_2",
    class == "Mais de 2 a 3 salários mínimos" ~ "between_2_3",
    class == "Mais de 3 a 5 salários mínimos" ~ "between_3_5",
    class == "Mais de 5 a 10 salários mínimos" ~ "between_5_10",
    class == "Mais de 10 salários mínimos" ~ "more_than_10",
    TRUE ~ class),
    #Fixing the city names
    city_name = str_remove(city_name, " \\([A-Z]{2}\\)")) %>% 
  mutate(statistic = round(as.numeric(statistic),2)) %>% 
  #taking out the class with no income
  filter(class != "Sem rendimento", class != "Fonte: IBGE - Censo Demográfico") 

#dataframe with the biggest income class per city (income class in %)
max_classes <- 
  brazil_gdp_location %>% 
  group_by(city_name) %>% 
  arrange(desc(statistic)) %>% 
  drop_na(statistic) %>% 
  summarize(statistic=max(statistic))

#Adding the city name to the previous df
max_classes_with_name <- max_classes  %>% 
  left_join(brazil_gdp_location, by=c("city_name", "statistic")) %>% 
  mutate(max_class = class) %>% 
  select(city_name, max_class)
  
#Adding previous information to our main dataframe
brazil_gdp_location <- 
  brazil_gdp_location %>% 
  left_join(max_classes_with_name, by="city_name") %>% 
  pivot_wider(names_from = class, values_from = statistic,values_fn = {mean})

```

```{r}

#Cleaning the city coordinates file - fixing the city codes
brazil_city_coordinates <- 
  brazil_city_coordinates %>% 
  mutate(city_code = as.numeric(substr(city_code, 1, 6)))

```


```{r}
#Cleaning the population db
brazil_population <- brazil_population %>% 
  #cleaning names
  janitor::clean_names() %>% 
  #mutating and fixing the city code to match others
  mutate(city_code = as.numeric(paste(cod_uf,substr(cod_munic, 1, 4), sep = "")), 
         #fixing the thousands separators in the population column
         population = case_when(
           city_code == 110020 ~ 369259,
           TRUE  ~ sapply(populacao_estimada, function(v) {as.numeric(gsub("\\.","", as.character(v)))}))) %>% 
  #selecting wished columns
  select(city_code, population)
```


```{r}
#Cleaning the GDP dataframe
brazil_gdp <- 
  brazil_gdp %>% 
  #selecting year
  filter(Ano == 2017) %>%
  #cleaning col names
  janitor::clean_names() %>% 
  #selecting columns
  select(c(nome_da_grande_regiao,
           codigo_do_municipio,
           nome_do_municipio,
           hierarquia_urbana_principais_categorias,
           produto_interno_bruto_a_precos_correntes_r_1_000,
           produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
           atividade_com_maior_valor_adicionado_bruto
           )) %>% 
  #renaming columns
  rename(region = nome_da_grande_regiao,
         city_code = codigo_do_municipio,
         city = nome_do_municipio,
         city_type = hierarquia_urbana_principais_categorias,
         gdp = produto_interno_bruto_a_precos_correntes_r_1_000,
         gdp_per_capita = produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
         main_activity = atividade_com_maior_valor_adicionado_bruto) %>% 
  #replacing decimal and thousand separators
  mutate(gdp = sapply(gdp, function(v) {as.numeric(gsub("\\,","", as.character(v)))}),
         gdp_per_capita = sapply(gdp_per_capita, function(v) {as.numeric(gsub("\\,","", as.character(v)))})) %>% 
  #removing last digit from the city code
  mutate(city_code = as.integer(substr(city_code, 1, nchar(city_code)-1)))
```

```{r}
#Joning dataframes

#Formating date columns that will be used as merge criteria
brazil_hospital_beds$merge_date=format(as.Date(brazil_hospital_beds$date), "%Y-%m")
brazil_cities$merge_date=format(as.Date(brazil_cities$date), "%Y-%m")

#Remove uneccessary columns
brazil_hospital_beds <- brazil_hospital_beds %>% select(-date, -city_name)

#Joining all cleaned databases
brazil_cities <- 
  brazil_cities %>% 
  left_join(brazil_city_coordinates, by = c("code" = "city_code")) %>% 
  left_join(brazil_population,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp_location,by = c("name" = "city_name")) %>% 
  left_join(brazil_hospital_beds, by = c("code", "merge_date")) %>% 
  select(-merge_date) #Remove the date used for merging


```

```{r}

#Creating and mutating new variables

#Creating daily_new_cases and cases_per_100k
brazil_cities <- brazil_cities %>% 
  arrange(code, date) %>% 
  group_by(code) %>% 
  mutate(daily_new_cases = cases - lag(cases),
         weekly_new_cases = cases - lag(cases, k=7),
         daily_cases_per_100k = (daily_new_cases / population) * 100000,
         weekly_cases_per_100k = (weekly_new_cases / population) * 100000)

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(daily_new_deaths = deaths - lag(deaths),
         daily_deaths_per_100k = (daily_new_deaths / population) * 100000,
         daily_mortality_rate = case_when(
           daily_new_cases == 0 ~0,
           TRUE ~ daily_new_deaths / daily_new_cases),
         daily_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ daily_deaths_per_100k / weekly_cases_per_100k),
         weekly_new_deaths = deaths - lag(deaths, k=7),
         weekly_deaths_per_100k = (weekly_new_deaths / population) * 100000,
         weekly_mortality_rate = case_when(
           weekly_new_cases == 0 ~ 0,
           TRUE ~ weekly_new_deaths / weekly_new_cases),
         weekly_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ weekly_deaths_per_100k / weekly_cases_per_100k))

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(active_infections = cases - lag(cases,14),
         recovered_infections = lag(cases,14) - deaths)

#Creating beds_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(beds_per_100k = (beds / population * 100000))

#Covid ICU rate of 5% (https://jamanetwork.com/journals/jama/fullarticle/2763188)

#Number of ICU beds required
brazil_cities <- brazil_cities %>%
  group_by(code, date) %>% 
  mutate(icu_capacity = (active_infections * 0.05)/beds)
```

```{r}

#Saving it in a CSV that will be used in Tableau for the visualizations
write.csv(brazil_cities,"brazil_cities_lat_long.csv")

```


```{r}

#Replacing NA's by 0 in the previous df
brazil_cities <- brazil_cities %>% mutate(daily_new_cases = ifelse(is.na(daily_new_cases),0 , daily_new_cases))
brazil_cities <- brazil_cities %>% mutate(population = ifelse(is.na(daily_new_cases), 0 , population))

#Creating new df per state (summarising by state)
brazil_cities_states <- brazil_cities %>%
  arrange(state, date) %>% 
  group_by(state,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) ))


#Saving all new dfs into csv's so it is possible to import to tableau
write.csv(brazil_cities_states,"brazil_cities_states.csv")

```