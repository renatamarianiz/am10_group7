---
title: "Analysis Brazil"
author: "Group 7"
date: "12/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Installing & checking Libraries
if(!is.element("tidyverse", installed.packages()[,1]))
{  install.packages("tidyverse")}
if(!is.element("cluster", installed.packages()[,1]))
{  install.packages("cluster")}
if(!is.element("factoextra", installed.packages()[,1]))
{  install.packages("factoextra")}
if(!is.element("Hmisc", installed.packages()[,1]))
{  install.packages("Hmisc")}
require(tidyverse)
require(Hmisc)
require(digest)
require(cluster)    # clustering algorithms
require(factoextra) # an umbrealla library for clustering algorithms & visualizations

#Importing libraries
library(sf)
library(extrafont)
loadfonts(device = "pdf")
library(tidyverse)
library(dplyr)
library(skimr)
library(vroom)
library(stringr)
library(openxlsx)
library(lubridate)
library(tidyverse)
library(Publish)
library(data.table)
```


# Group 7 Final Project

## Background

Coronavirus Disease 2019(COVID-19) has caused an unprecedented threat to people’s health status on a global scale. And in our data visualization, we want to focus on the largest country in South America: Brazil, which is the world’s fifth-largest country by area and the sixth most populous. Until today, a total of almost 6.4 million COVID cases have been confirmed while 5.3 million of them have already recovered. 

## Objectives

We aim to thoroughly understand and visualize Brazil’s COVID cases evolution in multiple dimensions: chronologic, geographic and demographic and  to explore different pandemic modes in different regions, ethnicity groups and periods.

## Explored Directions

1. Covid spread within the first months
2. Mortality Rate and Cases per City and State
3. Impact of demographic factors (population / gdp) on mortality rate
4. Impact of human measures (testing capabilities / lockdown) on moratality rate
5. In-depth analysis of Covids development in Sao Paulo
6. Creation a clustering algorithm

## Description of Story

"_It is not an alarming situation_" - Jair Bolsonaro, President of Brazil (26th January 2020)

Eight months later Brazil has reached a grim winners podium, ranking third in terms of total COVID cases and second in COVID related deaths worldwide. Through this visual analysis we want to retrace the spread and influential factors that played a role during the last months of this pandemic.

Looking at the procedural spread of Covid, one can see that the disease originated in international hubs - São Paulo and Rio de Janeiro - quickly reaching the capital - Brasilia. Following small-scale, local, expansions in these areas, the hotspot of the pandemic, however, moved towards Brazil's lowly populated northern region. After two months, the Virus reached most of Brazil, hitting the highly populated southern shore especially hard. After a closer look at these differing trends, the South, maily a rich region of Brazil, has one of the highest mortality rates. Notwithstanding, this region has the lowest number of cases per one hundred thousand inhabitants in the whole country!

When looking at the southern states, São Paulo distinguishes itself from the other states by having a significantly higher population and relatively low number of cases per 100.000 inhabitants. In addition, when comparing the development of the pandemics across this region, we can see that São Paulo by far outgrew other states in terms of cumulative number of cases as well as in the speed of the spread.

Now focusing on São Paulo, we can observe that mortality rate is higher in the coastal zone, where the state's metropolises and thus the majority of the population is concentrated. Although this doesn't explain the difference between the high rate of mortality and low number of cases per 100.000 inhabitants, it shows that the mortality is higher in big regional capitals and metropolitan cities. Furthermore, we could also find a positive correlation between population and daily mortality rate, which explains our initial findings.

By looking at São Paulo's daily trends, we identified an interesting phenomena. While a usual country's deaths peak around two or three weeks after cases have peaked, this trend was shown reversely. Thus indicating that there was an external factor influencing these trends. 

Local news suggest that the testing rate in São Paulo was [significantly scaled up around the 14th of May](https://g1.globo.com/sp/sao-paulo/noticia/2020/04/20/sp-tera-testagem-em-massa-para-coronavirus-a-partir-de-15-de-maio-segundo-vice-governador.ghtml), which could mean a more even distribution of COVID tests among heavy- and mild-symptoms. Thus, offering a possible situation for the decrease in mortality. On the other hand, there is also an interesting distribution of testing across Brazil. Brasilia has considerably more cases than São Paulo, while at the same time having a much lower daily mortality. News on the 18th of June say that while [São Paulo had only tested 1.31% of the population, Brasilia reached 10% of its inhabitants](https://agenciabrasilia.df.gov.br/2020/06/18/df-ja-testou-10-da-populacao-para-covid-19/), exceeding numbers even from the United States. The question that arises is whether Brasilia had a preferential treatment for being the capital of the country.

When the testing rate scaled up and hence more cases detected, Brazilian government took more stringent actions such as a lockdown.  Daily trends of cases, deaths and mortality, for São Paulo graphically show the effect of lockdown in the state. According to the state government, [São Paulo passed 3 million COVID-19 tests](https://www.saopaulo.sp.gov.br/ultimas-noticias/governo-de-sao-paulo-atualiza-informacoes-sobre-o-combate-ao-coronavirus-4/) on the 14th of August, having a daily increase of 3000% in testing. This highlights the difference between tested cases before and after the lockdown, where mortality decreased but the number of cases increased. 

Finally, we used a machine learning algorithm based on k-means to divide the cities in Brazil into clusters, trying to categorize them based on their COVID-19 and demographic statistics. Clusters 3 and 4 represent cities that still have a high number of cases and deaths, but a low mortality rate. Cities in cluster 4 are specifically Rio and São Paulo, highly populated and dense cities. On the other hand, group 3 consists of medium sized cities, maily capitals of states, that are spread throughout the country. Clusters 1 and 2 consist of small towns, with low daily cases and deaths. However, cluster 2 shows a higher mortality rate than 1.

Concludingly we believe that the regional differences in testing capacity, along with the missing data points made it difficult to precisely draw conclusions on the main influencers covid of spread throughout Brazil. Nevertheless, throughout our analysis, we have been able to show that both population size, as well as city type (density) had a significant effect on the mortality rate within cities. However, more in depth data would be required in order to trace this effect back in a more significant fashion. Interestingly, we also discovered one possible cause for the highly differing mortality rates throughout Brazil's states, believing that the high variability in testing availability is responsible for this.

## Datasets
1.	https://www.kaggle.com/unanimad/corona-virus-brazil	
2.  https://www.ibge.gov.br/geociencias/organizacao-do-territorio/15774-malhas.html?=&t=acesso-ao-produto
3.  https://www.ibge.gov.br/estatisticas/sociais/populacao/9103-estimativas-de-populacao.html?=&t=resultados
4.  https://www.ibge.gov.br/estatisticas/economicas/contas-nacionais/9088-produto-interno-bruto-dos-municipios.html?=&t=downloads
5.  https://sidra.ibge.gov.br/Tabela/3563
6.  http://tabnet.datasus.gov.br/cgi/deftohtm.exe?cnes/cnv/leiintbr.def

## Data Cleaning 

```{r}
## Importing Data
brazil_covid19 <- vroom("data/brazil_covid19.csv") #Covid Information
brazil_cities <- vroom("data/brazil_covid19_cities.csv") #City Information
brazil_city_coordinates <- vroom("data/brazil_cities_coordinates.csv") #City Coordinates
brazil_population <- vroom(file = "data/pop_by_city.csv") #Population Information
brazil_gdp <- vroom("data/PIB dos Munic¡pios - base de dados 2010-2017.csv") #GDP Information
brazil_gdp_location <- read.xlsx(xlsxFile = "data/brazil_gdp_city.xlsx", fillMergedCells = TRUE, colNames = TRUE) #Income info
brazil_hospital_beds <- vroom(file = "data/Itensive_Care Beds_Brazil_2020.csv", delim=';') #Number of hospital beds
```

```{r}
#Cleaning the hospital beds (intensive care) dataframe
brazil_hospital_beds <- 
  brazil_hospital_beds %>% 
  #cleaning column names
  janitor::clean_names() %>% 
  #transforming previously char. date to numeric
  mutate(x2020_jul = as.numeric(x2020_jul),
         x2020_ago = as.numeric(x2020_ago)) %>% 
  #pivoting the data-frame into a long-format
  pivot_longer(!municipio,names_to = "date",values_to = "beds") %>% 
  #mutating the dates - transforming to a date
  mutate(date = case_when(
    date == "x2020_jan" ~ dmy(15012020),
    date == "x2020_fev" ~ dmy(15022020),
    date == "x2020_mar" ~ dmy(15032020),
    date == "x2020_abr" ~ dmy(15042020),
    date == "x2020_mai" ~ dmy(15052020),
    date == "x2020_jun" ~ dmy(15062020),
    date == "x2020_jul" ~ dmy(15072020),
    date == "x2020_ago" ~ dmy(15082020),
    date == "x2020_set" ~ dmy(15092020),
    date == "x2020_out" ~ dmy(15102020)),
    #Fixing the city name for Alta Floresta D'Oeste
    city_name = trimws(str_extract("110001 Alta Floresta D'Oeste", "\\s.*"),"l"),
    #Seperate the code from the city name found within the municipio
    code = as.numeric(str_extract(municipio, "(\\d{6})"))) %>% 
  #Selecting the column of interest (beds), as well as those required for a merge (code, date)
  select(code, city_name, date, beds)
```


```{r}
#cleaning income dataframe
brazil_gdp_location <- brazil_gdp_location %>% 
  #cleaning column names
  janitor::clean_names() %>% 
  #renaming columns to match english names
  rename(
    city_name = municipio,
    class = classes_de_rendimento_nominal_mensal_domiciliar_per_capita, #income class
    statistic = ano_x_situacao_do_domicilio #percentage of population in this income class
    ) %>% 
  #filtering and mutating income classes (compared to the base salary in Brazil)
  filter(class != "Total") %>% 
  #Renaming income classes to more intuitive names
  #All percentages are percentage of population living of that percentage of base salary
  mutate(class = case_when(
    class == "Total" ~ "Total",
    class == "Até 1/8 de salário mínimo" ~ "below_0.125",
    class == "Mais de 1/8 a 1/4 de salário mínimo" ~ "between_0.125_0.25",
    class == "Mais de 1/4 a 1/2 salário mínimo" ~ "between_0.25_0.5",
    class == "Mais de 1/2 a 1 salário mínimo" ~ "between_0.5_1",
    class == "Mais de 1 a 2 salários mínimos" ~ "between_1_2",
    class == "Mais de 2 a 3 salários mínimos" ~ "between_2_3",
    class == "Mais de 3 a 5 salários mínimos" ~ "between_3_5",
    class == "Mais de 5 a 10 salários mínimos" ~ "between_5_10",
    class == "Mais de 10 salários mínimos" ~ "more_than_10",
    TRUE ~ class),
    #Fixing the city names by removing state codes
    city_name = str_remove(city_name, " \\([A-Z]{2}\\)")) %>% 
  mutate(statistic = round(as.numeric(statistic),2)) %>% 
  #Removing the class with no income as this contains mainly NAs
  filter(class != "Sem rendimento", class != "Fonte: IBGE - Censo Demográfico") 


#creating a Dataframe with the modal income class for every city (income class in %)
max_classes <- 
  brazil_gdp_location %>% 
  group_by(city_name) %>% 
  arrange(desc(statistic)) %>% 
  drop_na(statistic) %>% 
  #finding the maximum percentage per each city
  summarise(statistic=max(statistic))

#Adding the city_names to the max_class dataframe containing maximum percentage for each city
max_classes_with_name <- max_classes  %>% 
  left_join(brazil_gdp_location, by=c("city_name", "statistic")) %>% 
  mutate(max_class = class) %>% 
  select(city_name, max_class)
  
#Adding previous information to our main dataframe
brazil_gdp_location <- 
  brazil_gdp_location %>% 
  left_join(max_classes_with_name, by="city_name") %>% 
  #pivoting wider to have one column for each income class, this is important to have one row per city & day later
  pivot_wider(names_from = class, values_from = statistic,values_fn = {mean})
```

```{r}
#Cleaning the city coordinates file - fixing the city codes
brazil_city_coordinates <- 
  brazil_city_coordinates %>% 
  #removing the last figure from coordinates as this is not included in other zip-code formats
  mutate(city_code = as.numeric(substr(city_code, 1, 6)))
```


```{r}
#Cleaning the population db
brazil_population <- brazil_population %>% 
  #cleaning names
  janitor::clean_names() %>% 
  #mutating and fixing the city code to match others
  mutate(city_code = as.numeric(paste(cod_uf,substr(cod_munic, 1, 4), sep = "")), 
         #fixing the thousands separators in the population column
         population = case_when(
           city_code == 110020 ~ 369259,
           TRUE  ~ sapply(populacao_estimada, function(v) {as.numeric(gsub("\\.","", as.character(v)))}))) %>% 
  #selecting wished columns
  select(city_code, population)
```


```{r}
#Cleaning the GDP dataframe
brazil_gdp <- 
  brazil_gdp %>% 
  #selecting year
  filter(Ano == 2017) %>%
  #cleaning col names
  janitor::clean_names() %>% 
  #selecting columns of interest, see below for english names
  select(c(nome_da_grande_regiao,
           codigo_do_municipio,
           nome_do_municipio,
           hierarquia_urbana_principais_categorias,
           produto_interno_bruto_a_precos_correntes_r_1_000,
           produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
           atividade_com_maior_valor_adicionado_bruto
           )) %>% 
  #renaming columns to english names
  rename(region = nome_da_grande_regiao,
         city_code = codigo_do_municipio,
         city = nome_do_municipio,
         city_type = hierarquia_urbana_principais_categorias,
         gdp = produto_interno_bruto_a_precos_correntes_r_1_000,
         gdp_per_capita = produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
         main_activity = atividade_com_maior_valor_adicionado_bruto) %>% 
  #replacing decimal and thousand separators as portugese use comma instead of .
  mutate(gdp = sapply(gdp, function(v) {as.numeric(gsub("\\,","", as.character(v)))}),
         gdp_per_capita = sapply(gdp_per_capita, function(v) {as.numeric(gsub("\\,","", as.character(v)))})) %>% 
  #removing last digit from the city code to match normed format
  mutate(city_code = as.integer(substr(city_code, 1, nchar(city_code)-1)))
```

```{r}
#Joning dataframes

#Formating date columns that will be used as merge criteria
#As these data-points are on a per-month basis we added a separate column for matching purposes
brazil_hospital_beds$merge_date=format(as.Date(brazil_hospital_beds$date), "%Y-%m")
brazil_cities$merge_date=format(as.Date(brazil_cities$date), "%Y-%m")

#Remove column used for merging as this has no more need
brazil_hospital_beds <- brazil_hospital_beds %>% select(-date, -city_name)

#Joining all cleaned databases 
brazil_cities <- 
  brazil_cities %>% 
  left_join(brazil_city_coordinates, by = c("code" = "city_code")) %>% 
  left_join(brazil_population,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp_location,by = c("name" = "city_name")) %>% 
  left_join(brazil_hospital_beds, by = c("code", "merge_date")) %>% 
  select(-merge_date) #Remove the date used for merging
```

```{r}
#Creating and mutating new variables
#Creating daily_new_cases and cases_per_100k
brazil_cities <- brazil_cities %>% 
  arrange(code, date) %>% 
  group_by(code) %>% 
  mutate(daily_new_cases = cases - lag(cases),
         weekly_new_cases = cases - lag(cases, k=7),
         daily_cases_per_100k = (daily_new_cases / population) * 100000,
         weekly_cases_per_100k = (weekly_new_cases / population) * 100000)

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(daily_new_deaths = deaths - lag(deaths),
         daily_deaths_per_100k = (daily_new_deaths / population) * 100000,
         #preventing division by zero issues
         daily_mortality_rate = case_when(
           daily_new_cases == 0 ~0,
           TRUE ~ daily_new_deaths / daily_new_cases),
         #preventing division by zero issues
         daily_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ daily_deaths_per_100k / weekly_cases_per_100k),
         weekly_new_deaths = deaths - lag(deaths, k=7),
         weekly_deaths_per_100k = (weekly_new_deaths / population) * 100000,
         #preventing division by zero issues
         weekly_mortality_rate = case_when(
           weekly_new_cases == 0 ~ 0,
           TRUE ~ weekly_new_deaths / weekly_new_cases),
         #preventing division by zero issues
         weekly_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ weekly_deaths_per_100k / weekly_cases_per_100k))

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(active_infections = cases - lag(cases,14),
         recovered_infections = lag(cases,14) - deaths)

#Creating beds_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(beds_per_100k = (beds / population * 100000))

#Covid ICU rate of 5% (https://jamanetwork.com/journals/jama/fullarticle/2763188)
#Number of ICU beds required based upon a ICU-rate of 5%
brazil_cities <- brazil_cities %>%
  group_by(code, date) %>% 
  mutate(icu_capacity = (active_infections * 0.05)/beds)
```

```{r}
#Saving it in a CSV that will be used in Tableau for the visualizations
write.csv(brazil_cities,"brazil_cities_lat_long.csv")
```


```{r}
#Replacing NA's by 0 in the previous df
brazil_cities <- brazil_cities %>% mutate(daily_new_cases = ifelse(is.na(daily_new_cases),0 , daily_new_cases))
brazil_cities <- brazil_cities %>% mutate(population = ifelse(is.na(daily_new_cases), 0 , population))

#Creating new df per state (summarising by state)
brazil_cities_states <- brazil_cities %>%
  arrange(state, date) %>% 
  group_by(state,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  #create binary variable indicating whether cases reached over 10k
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  #count cumulative days since first occurrence of 10k cases
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) ))

#Saving all new dfs into csv's so it is possible to import to tableau
write.csv(brazil_cities_states,"brazil_cities_states.csv")
```

## Cluster Analysis

```{r}

#Running a cluster analysis to detect clusters in regional Covid outbreaks

#Creating a new, more compact, dataframe to be used for clustering
filtered_data <- 
  brazil_cities %>%
  #running only on all available cases in this November
  filter(date >= mdy("11/01/2020")) %>%
  group_by(city_name) %>% 
  summarise(daily_new_cases = mean(daily_new_cases),
            daily_new_deaths = mean(daily_new_deaths),
            population = mean(population),
            gdp = mean(gdp),
            daily_mortality_rate = mean(daily_mortality_rate)) %>% 
  filter(daily_new_cases!=0 & daily_mortality_rate!=0 & daily_new_deaths!=0 ) %>% 
  drop_na() #drop all NA values

#Specify columns to be used for clustering
cluster_data <- 
  filtered_data %>% 
  select(daily_new_cases,daily_new_deaths,population,gdp, daily_mortality_rate) %>%
  scale()

# we'll use elbow method to find the best number of cluster 
tot_withinss <- map_dbl(1:10,  function(k){
  model <- kmeans(x = cluster_data, centers = k,iter.max = 100, nstart = 10)
  model$tot.withinss})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:10 ,
  tot_withinss = tot_withinss
)

# Plot the elbow plot
ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:20)

#Here is a short way of producing the elbow chart using "fviz_nbclust" function. 
fviz_nbclust(cluster_data,kmeans, method = "wss")+
  labs(subtitle = "Elbow method")

# From the plot below we decide to use 4 clusters for our analysis
```

```{r}
#Using the previously found values of k we now cluster the results
model_km <- eclust(cluster_data, "kmeans", k = 4,nstart = 50, graph = FALSE)
#Check the sizes of the clusters
model_km$size
xa<-data.frame(cluster=as.factor(c(1:4)),model_km$centers)
xa2k3<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)

graphknn<-
  ggplot(xa2k3, aes(x = variable, y = value)) + 
  geom_hline(yintercept=0, color = "lightgrey") +
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1) +
  geom_point(size=1,shape=4) +
  theme_minimal() +
  theme(text = element_text(size=9, family = "Avenir Book"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(angle=45, hjust=1, family = "Avenir Book"),
        legend.title=element_text(size=7, family = "Avenir Book"),
        legend.text = element_text(size=7, family = "Avenir Book"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 12, family = "Avenir Book"),
        plot.subtitle = element_text(size = 10, face = "italic", family = "Avenir Book")) +
  labs(title= "Cluster 4 Focuses on Highly Impacted Regions",
       subtitle = "K-means Kluster Algorithm with 4 Clusters") +
  scale_color_manual(values=c("#B7D5ED", "#80B3D8","#F6C993","#D27532")) +
  scale_x_discrete(labels=c("daily_new_cases" = "Daily Cases", 
                            "daily_new_deaths" = "Daily Deaths",
                            "population" = "Population",
                            "gdp" = "GDP",
                            "daily_mortality_rate" = "Daily Mortality Rate"))

graphknn
```

```{r}
# eclust function (part of factoextra) makes it easier to visuliaze clustering results
model_km2 <- eclust(cluster_data, "kmeans", k = 2,nstart = 50, graph = FALSE)
model_km2$size
model_km3 <- eclust(cluster_data, "kmeans", k = 3,nstart = 50, graph = FALSE)
model_km3$size
model_km4 <- eclust(cluster_data, "kmeans", k = 4,nstart = 50, graph = FALSE)
model_km4$size
 
# plots to compare
#I use the fviz_cluster function which is part of the`factoextra` library
p1 <- fviz_cluster(model_km2, geom = "point", data = cluster_data) + ggtitle("k = 2")
p2 <- fviz_cluster(model_km3, geom = "point",  data = cluster_data) + ggtitle("k = 3")
p3 <- fviz_cluster(model_km4, geom = "point",  data = cluster_data) + ggtitle("k = 4")
library(gridExtra)
grid.arrange(p1, p2,p3, nrow = 2)
```

```{r}
filtered_data$Cluster <- model_km4$cluster
write.csv(filtered_data,"/Users/remzanella/Desktop/cluster_test.csv")
```