---
title: "Analysis Brazil"
author: "Jan Mölich"
date: "11/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(skimr)
library(vroom)
library(stringr)
library(openxlsx)
library(lubridate)
library(tidyverse)
library(Publish)
library(data.table)
if(!is.element("tidyverse", installed.packages()[,1]))
{  install.packages("tidyverse")}
if(!is.element("cluster", installed.packages()[,1]))
{  install.packages("cluster")}
if(!is.element("factoextra", installed.packages()[,1]))
{  install.packages("factoextra")}
if(!is.element("Hmisc", installed.packages()[,1]))
{  install.packages("Hmisc")}

require(tidyverse)
require(Hmisc)
require(digest)
require(cluster)    # clustering algorithms
require(factoextra) # an umbrealla library for clustering algorithms & visualizations


```


```{r}

## Importing Data
brazil_covid19 <- vroom("data/brazil_covid19.csv")
brazil_cities <- vroom("data/brazil_covid19_cities.csv")
brazil_city_coordinates <- vroom("data/brazil_cities_coordinates.csv")
brazil_population <- vroom(file = "data/pop_by_city.csv")
brazil_gdp <- vroom("data/PIB dos Munic¡pios - base de dados 2010-2017.csv")
brazil_gdp_location <- read.xlsx(xlsxFile = "data/brazil_gdp_city.xlsx", fillMergedCells = TRUE, colNames = TRUE) 
brazil_hospital_beds <- vroom(file = "data/Itensive_Care Beds_Brazil_2020.csv",
                                    delim=';')

brazil_hospital_beds <- brazil_hospital_beds %>% 
  janitor::clean_names() %>% 
  mutate(x2020_jul = as.numeric(x2020_jul),
         x2020_ago = as.numeric(x2020_ago)) %>% 
  pivot_longer(!municipio,names_to = "date",values_to = "beds") %>% 
  mutate(date = case_when(
    date == "x2020_jan" ~ dmy(15012020),
    date == "x2020_fev" ~ dmy(15022020),
    date == "x2020_mar" ~ dmy(15032020),
    date == "x2020_abr" ~ dmy(15042020),
    date == "x2020_mai" ~ dmy(15052020),
    date == "x2020_jun" ~ dmy(15062020),
    date == "x2020_jul" ~ dmy(15072020),
    date == "x2020_ago" ~ dmy(15082020),
    date == "x2020_set" ~ dmy(15092020),
    date == "x2020_out" ~ dmy(15102020)),
    city_name = trimws(str_extract("110001 Alta Floresta D'Oeste", "\\s.*"),"l"),
    code = as.numeric(str_extract(municipio, "(\\d{6})"))) %>% 
  select(code, city_name, date, beds)
  
skim(brazil_hospital_beds)

brazil_gdp_location <- brazil_gdp_location %>% 
  janitor::clean_names() %>% 
  rename(
    city_name = municipio,
    class = classes_de_rendimento_nominal_mensal_domiciliar_per_capita,
    statistic = ano_x_situacao_do_domicilio
    ) %>% 
  filter(class != "Total") %>% 
  mutate(class = case_when(
    class == "Total" ~ "Total",
    class == "Até 1/8 de salário mínimo" ~ "below_0.125",
    class == "Mais de 1/8 a 1/4 de salário mínimo" ~ "between_0.125_0.25",
    class == "Mais de 1/4 a 1/2 salário mínimo" ~ "between_0.25_0.5",
    class == "Mais de 1/2 a 1 salário mínimo" ~ "between_0.5_1",
    class == "Mais de 1 a 2 salários mínimos" ~ "between_1_2",
    class == "Mais de 2 a 3 salários mínimos" ~ "between_2_3",
    class == "Mais de 3 a 5 salários mínimos" ~ "between_3_5",
    class == "Mais de 5 a 10 salários mínimos" ~ "between_5_10",
    class == "Mais de 10 salários mínimos" ~ "more_than_10",
    TRUE ~ class),
    city_name = str_remove(city_name, " \\([A-Z]{2}\\)")) %>% 
  mutate(statistic = round(as.numeric(statistic),2)) %>% 
  filter(class != "Sem rendimento", class != "Fonte: IBGE - Censo Demográfico") 
  
max_classes <- brazil_gdp_location %>% 
  group_by(city_name) %>% 
  arrange(desc(statistic)) %>% 
  drop_na(statistic) %>% 
  summarize(statistic=max(statistic))
  
max_classes_with_name <- max_classes  %>% 
  left_join(brazil_gdp_location, by=c("city_name", "statistic")) %>% 
  mutate(max_class = class) %>% 
  select(city_name, max_class)
  
brazil_gdp_location <- brazil_gdp_location %>% 
  left_join(max_classes_with_name, by="city_name") %>% 
  pivot_wider(names_from = class, values_from = statistic,values_fn = {mean})

brazil_city_coordinates <- brazil_city_coordinates %>% 
  mutate(city_code = as.numeric(substr(city_code, 1, 6)))

#DELETE
#brazil_gdp %>% filter(str_detect(nome,"ana"))
#brazil_cities %>% filter(str_detect(name,"Sant'Ana"))

#Cleaning the population db
brazil_population <- brazil_population %>% 
  janitor::clean_names() %>% 
  mutate(city_code = as.numeric(paste(cod_uf,substr(cod_munic, 1, 4), sep = "")), 
         population = case_when(
      city_code == 110020 ~ 369259,
      TRUE  ~ sapply(populacao_estimada, function(v) {as.numeric(gsub("\\.","", as.character(v)))}))) %>% 
  select(city_code, population)

#Cleaning the GDP db
brazil_gdp <- 
  brazil_gdp %>% 
  #selecting year
  filter(Ano == 2017) %>%
  #cleaning col names
  janitor::clean_names() %>% 
  #selecting columns
  select(c(nome_da_grande_regiao,
           codigo_do_municipio,
           nome_do_municipio,
           hierarquia_urbana_principais_categorias,
           produto_interno_bruto_a_precos_correntes_r_1_000,
           produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
           atividade_com_maior_valor_adicionado_bruto
           )) %>% 
  #renaming columns
  rename(region = nome_da_grande_regiao,
         city_code = codigo_do_municipio,
         city = nome_do_municipio,
         city_type = hierarquia_urbana_principais_categorias,
         gdp = produto_interno_bruto_a_precos_correntes_r_1_000,
         gdp_per_capita = produto_interno_bruto_per_capita_a_precos_correntes_r_1_00,
         main_activity = atividade_com_maior_valor_adicionado_bruto) %>% 
  #replacing decimal and thousand separators
  mutate(gdp = sapply(gdp, function(v) {as.numeric(gsub("\\,","", as.character(v)))}),
         gdp_per_capita = sapply(gdp_per_capita, function(v) {as.numeric(gsub("\\,","", as.character(v)))})) %>% 
  #removing last digit from the city code
  mutate(city_code = as.integer(substr(city_code, 1, nchar(city_code)-1)))

brazil_hospital_beds$merge_date=format(as.Date(brazil_hospital_beds$date), "%Y-%m")
brazil_cities$merge_date=format(as.Date(brazil_cities$date), "%Y-%m")

brazil_hospital_beds <- brazil_hospital_beds %>% select(-date, -city_name) #remove uneccessary columns

#Joining databases (coordinates and population)
brazil_cities <- brazil_cities %>% 
  left_join(brazil_city_coordinates, by = c("code" = "city_code")) %>% 
  left_join(brazil_population,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp,by = c("code" = "city_code")) %>% 
  left_join(brazil_gdp_location,by = c("name" = "city_name")) %>% 
  left_join(brazil_hospital_beds, by = c("code", "merge_date")) %>% 
  select(-merge_date) #Remove the date used for merging
  

#Creating daily_new_cases and cases_per_100k
brazil_cities <- brazil_cities %>% 
  arrange(code, date) %>% 
  group_by(code) %>% 
  mutate(daily_new_cases = cases - lag(cases),
         weekly_new_cases = cases - lag(cases, k=7),
         daily_cases_per_100k = (daily_new_cases / population) * 100000,
         weekly_cases_per_100k = (weekly_new_cases / population) * 100000)

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(daily_new_deaths = deaths - lag(deaths),
         daily_deaths_per_100k = (daily_new_deaths / population) * 100000,
         daily_mortality_rate = case_when(
           daily_new_cases == 0 ~0,
           TRUE ~ daily_new_deaths / daily_new_cases),
         daily_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ daily_deaths_per_100k / weekly_cases_per_100k),
         weekly_new_deaths = deaths - lag(deaths, k=7),
         weekly_deaths_per_100k = (weekly_new_deaths / population) * 100000,
         weekly_mortality_rate = case_when(
           weekly_new_cases == 0 ~ 0,
           TRUE ~ weekly_new_deaths / weekly_new_cases),
         weekly_mortality_rate_per_100k = case_when(
           weekly_cases_per_100k == 0 ~ 0,
           TRUE ~ weekly_deaths_per_100k / weekly_cases_per_100k))

#Creating daily_new_deaths and deaths_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(active_infections = cases - lag(cases,14),
         recovered_infections = lag(cases,14) - deaths)

#Creating beds_per_100k
brazil_cities <- brazil_cities %>% 
  mutate(beds_per_100k = (beds / population * 100000))

#Covid ICU rate of 5% (https://jamanetwork.com/journals/jama/fullarticle/2763188)

#Number of ICU beds required
brazil_cities <- brazil_cities %>%
  group_by(code, date) %>% 
  mutate(icu_capacity = (active_infections * 0.05)/beds)



write.csv(brazil_cities,"brazil_cities_lat_long.csv")
```


```{r}

brazil_cities <- brazil_cities %>% mutate(daily_new_cases = ifelse(is.na(daily_new_cases),0 , daily_new_cases))



brazil_cities_region <- brazil_cities %>%
  arrange(region, date) %>% 
  group_by(region,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) )) 

brazil_cities_type <- brazil_cities %>%
  arrange(city_type, date) %>% 
  group_by(city_type,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) )) 

brazil_cities_states <- brazil_cities %>%
  arrange(state, date) %>% 
  group_by(state,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) ))
 

brazil_cities <- brazil_cities %>% mutate(population = ifelse(is.na(daily_new_cases), 0 , population))

brazil_cities_gdp <- brazil_cities



brazil_cities_gdp <- brazil_cities_gdp %>% 
  mutate(gdp_group = case_when(
    gdp_per_capita <= 10000 ~ 1,
    gdp_per_capita <= 20000 ~ 2,
    gdp_per_capita <= 30000 ~ 3,
    gdp_per_capita <= 40000 ~ 4,
    gdp_per_capita >= 40000 ~ 5
  ))

brazil_cities_gdp_2 <- brazil_cities_gdp

brazil_cities_gdp <- brazil_cities_gdp %>%
  arrange(gdp_group, date) %>% 
  group_by(gdp_group,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases)) %>% 
  mutate(cumsum= cumsum(daily_cases_region))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) ))


brazil_cities_gdp_2 <- brazil_cities_gdp_2 %>%
  arrange(gdp_group, date) %>% 
  group_by(gdp_group,date) %>%
  summarise(daily_cases_region= sum(daily_new_cases), population=sum(population)) %>% 
  mutate(cumsum_by_m= cumsum(daily_cases_region)/population)%>% 
  mutate(cumsum= cumsum(daily_cases_region)) %>%
  mutate(region_days_since_10000_cases = ifelse (cumsum < 10000,0,1))%>% 
  mutate(region_days_since_10000_cases = ifelse (cumsum< 10000,0, cumsum(region_days_since_10000_cases) ))


write.csv(brazil_cities_region,"brazil_cities_region.csv")
write.csv(brazil_cities_states,"brazil_cities_states.csv")
write.csv(brazil_cities_type, "brazil_cities_type.csv")
write.csv(brazil_cities_gdp, "brazil_cities_gdp.csv")
 

```

```{r}
ggplot(brazil_cities_region, aes(x= region_days_since_10000_cases, y= cumsum, color=region))+ geom_point()

ggplot(brazil_cities_type, aes(x= region_days_since_10000_cases, y= cumsum, color=city_type))+ geom_point()

ggplot(brazil_cities_states, aes(x= region_days_since_10000_cases, y= cumsum, color=state))+ geom_point()

ggplot(brazil_cities_gdp, aes(x= region_days_since_10000_cases, y= cumsum, color=gdp_group))+ geom_point()


ggplot(brazil_cities_gdp_2, aes(x= region_days_since_10000_cases, y= cumsum_by_m, color=gdp_group))+ geom_point()

```

```{r}



analysis_1 %>% 
  filter(capital == TRUE) %>% 
  ggplot(aes(y=max_cases_per_100k, x=population, color = capital, label = name)) + geom_point() +
  geom_text() + 
  scale_x_log10() +
  scale_y_log10()
```

```{r}
library(zoo)
ggplot(brazil_cities) + geom_boxplot(aes(x=max_class, y=cases_per_100k), alpha=0.02)

classes_over_time <- brazil_cities %>% 
  drop_na(cases_per_100k, max_class) %>% 
  select(max_class, cases_per_100k, date) %>% 
  group_by(date, max_class) %>% 
  summarise(avg_cases_100k = mean(cases_per_100k)) %>% 
  mutate(roll_mean_cases_100k = rollmean(avg_cases_100k, k=6, na.pad = T))
  
  

ggplot(classes_over_time, aes(x=date,y=avg_cases_100k)) + geom_line()
```



```{r}
brazil_cities <- vroom("data/brazil_cities_lat_long.csv")

#linear regression analysis 
#we'll use the latest day of cases data to predict the future cases, if not we couldn't run a clustering analysis, it says that "vector size is 14.6G.

cluster_data <- brazil_cities %>%
  filter(date == "11/25/2020") %>% 
 select(weekly_cases_per_100k,weekly_deaths_per_100k,population,gdp, weekly_mortality_rate_per_100k, lat, long) %>%
  filter(weekly_cases_per_100k!=0 & weekly_mortality_rate_per_100k!=0) %>% 
  drop_na() %>% 
  scale()


# we'll use elbow method to find the best number of cluster 

tot_withinss <- map_dbl(1:10,  function(k){
  model <- kmeans(x = cluster_data, centers = k,iter.max = 100, nstart = 10)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:10 ,
  tot_withinss = tot_withinss
)

# Plot the elbow plot
ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:20)

#Here is a short way of producing the elbow chart using "fviz_nbclust" function. 
fviz_nbclust(cluster_data,kmeans, method = "wss")+
  labs(subtitle = "Elbow method")

# from the plot below we decide to use 6 clusters 

```

```{r}

model_km <- eclust(cluster_data, "kmeans", k = 4,nstart = 50, graph = FALSE)

#Check the sizes of the clusters
model_km$size


xa<-data.frame(cluster=as.factor(c(1:4)),model_km$centers)
xa2k3<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)

graphknn<-ggplot(xa2k3, aes(x = variable, y = value))+  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+ geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),legend.title=element_text(size=5),legend.text = element_text(size=5))+ggtitle("K-means Centers k=6")


graphknn


```


```{r}
# eclust function (part of factoextra) makes it easier to visuliaze clustering results
model_km2 <- eclust(cluster_data, "kmeans", k = 2,nstart = 50, graph = FALSE)
model_km2$size
model_km3 <- eclust(cluster_data, "kmeans", k = 3,nstart = 50, graph = FALSE)
model_km3$size
model_km4 <- eclust(cluster_data, "kmeans", k = 4,nstart = 50, graph = FALSE)
model_km4$size
model_km5 <- eclust(cluster_data, "kmeans", k = 5,nstart = 50, graph = FALSE)
model_km5$size
 
# plots to compare
#I use the fviz_cluster function which is part of the`factoextra` library
p1 <- fviz_cluster(model_km2, geom = "point", data = cluster_data) + ggtitle("k = 2")
p2 <- fviz_cluster(model_km3, geom = "point",  data = cluster_data) + ggtitle("k = 3")
p3 <- fviz_cluster(model_km4, geom = "point",  data = cluster_data) + ggtitle("k = 4")
p4 <- fviz_cluster(model_km5, geom = "point",  data = cluster_data) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2,p3,p4, nrow = 2)
```

